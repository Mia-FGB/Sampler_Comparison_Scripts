{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with MARTi data \n",
    "\n",
    "https://docs.google.com/document/d/1uldwa4ep4Pr1NrD6hmcmLY3AL-vCiniPYVSswhX1kF8/edit\n",
    "\n",
    "Last editted - 29th July 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in and polishing data\n",
    "\n",
    "Using summarised data and performing the analysis at different taxonomic levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the data\n",
    "raw_data = pd.read_csv('../samp_comp_0624_marti/samp_comp_summed_0624.csv')\n",
    "# Melt the raw_data dataframe\n",
    "raw_data_long = raw_data.melt(id_vars=['Taxon', 'NCBI_ID', 'Rank'], var_name='Sample_ID', value_name='Count')\n",
    "\n",
    "metadata = pd.read_csv('../old_parameters_MARTI_samp_comp_read_data/Phyloseq_data/Sample_table.csv')\n",
    "\n",
    "# Merge the melted raw_data with seq_info on 'Sample_ID'\n",
    "merged_data = pd.merge(raw_data_long, metadata, on='Sample_ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter to one taxonomic rank\n",
    "filtered_data = merged_data[(merged_data['Rank'] == 'genus') &\n",
    "                            (merged_data['Count'] > 0) #need this for aggregation to work\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating the data\n",
    "\n",
    "Creating a summary for each Sample, number of unique taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to count unique taxa per Sample\n",
    "data = filtered_data.groupby('Sample_ID').agg({\n",
    "    'Taxon': pd.Series.nunique, #This is giving the same for each, think I need to remove count = 0 first\n",
    "    'Location': 'first',\n",
    "    'Sampler': 'first',\n",
    "    'Repeat': 'first',\n",
    "    'Flow_rate': 'first',\n",
    "    'Sample_length': 'first',\n",
    "    'Air_volume': 'first',\n",
    "    'NumReads': 'first',\n",
    "    'MeanLength': 'first',\n",
    "    'N50Length': 'first',\n",
    "    'Shortest': 'first',\n",
    "    'Longest': 'first',\n",
    "    'DNA_yield': 'first',\n",
    "    'Insect': 'first'\n",
    "}).reset_index().rename(columns={'Taxon': 'num_unique_taxa'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making variables readable by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample_ID            object\n",
       "num_unique_taxa       int64\n",
       "Location           category\n",
       "Sampler              object\n",
       "Repeat                int64\n",
       "Flow_rate             int64\n",
       "Sample_length         int64\n",
       "Air_volume            int64\n",
       "NumReads              int64\n",
       "MeanLength          float64\n",
       "N50Length             int64\n",
       "Shortest              int64\n",
       "Longest               int64\n",
       "DNA_yield           float64\n",
       "Insect               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.replace(',','', regex=True)\n",
    "\n",
    "data.Location = data.Location.astype('category')# Convert 'NumReads', 'N50Length', and 'Longest' from object to numeric\n",
    "data['NumReads'] = pd.to_numeric(data['NumReads'], errors='coerce')\n",
    "data['N50Length'] = pd.to_numeric(data['N50Length'], errors='coerce')\n",
    "data['Longest'] = pd.to_numeric(data['Longest'], errors='coerce')\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = data.drop(['num_unique_taxa'], axis=1)\n",
    "y = data['num_unique_taxa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), ['Repeat', 'Flow_rate', 'Sample_length', 'Air_volume', 'NumReads', 'MeanLength', 'N50Length', 'Shortest', 'Longest', 'DNA_yield']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Location', 'Sampler', 'Insect', 'Sample_ID'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 632.1850374999999\n"
     ]
    }
   ],
   "source": [
    "# Create the pipeline with preprocessor and Random Forest model\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('classifier', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "# ])\n",
    "\n",
    "# # Split data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "#high MSE indicates that the model is not very accurate, probably because I don't have much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), ['Flow_rate', 'Sample_length', 'Air_volume', 'NumReads', 'MeanLength', 'N50Length', 'DNA_yield']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['Location', 'Sampler'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Specify columns to include (ignore 'Repeat & Sample_ID', 'Insect', Longest & Shortest)\n",
    "columns_to_include = ['Flow_rate', 'Sample_length', 'Air_volume', 'NumReads', 'MeanLength', 'N50Length', 'DNA_yield', 'Location', 'Sampler', ]\n",
    "\n",
    "# Filter columns\n",
    "X_filtered = X[columns_to_include]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model to create a visual tree - slightly different way to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -19.673 (9.460)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "from sklearn.tree import export_graphviz\n",
    "from numpy import mean, std\n",
    "import pydot\n",
    "from subprocess import check_call\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['num_unique_taxa'], axis=1)\n",
    "y = data['num_unique_taxa']\n",
    "\n",
    "# Preprocess the data - using the preprocessing from the previous code\n",
    "X_preprocessed = preprocessor.fit_transform(X_filtered) #Taking a subset of columns specified above\n",
    "#X_preprocessed = preprocessor.fit_transform(X)#Will take all columns in\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_preprocessed, y)\n",
    "\n",
    "# Evaluate the model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X_preprocessed, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# Report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "\n",
    "# Export one of the trees in the Random Forest\n",
    "estimator = model.estimators_[0]\n",
    "\n",
    "# Get feature names from preprocessing\n",
    "feature_names = (preprocessor.transformers_[0][2] +\n",
    "                  list(preprocessor.transformers_[1][1].get_feature_names_out()))\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='../Images/tree.dot',\n",
    "                feature_names=feature_names,\n",
    "                rounded=True, proportion=False,\n",
    "                precision=2, filled=True)\n",
    "\n",
    "# Convert dot file to PNG image\n",
    "check_call(['dot', '-Tpng', '../Images/tree.dot', '-o', '../Images/random_forest_tree.png'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samp_comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
